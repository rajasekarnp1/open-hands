# Provider configurations for the LLM API Aggregator

providers:
  openrouter:
    name: "OpenRouter"
    display_name: "OpenRouter"
    provider_type: "free"
    base_url: "https://openrouter.ai/api/v1"
    priority: 1
    rate_limit:
      requests_per_minute: 20
      requests_per_day: 50
      concurrent_requests: 5
    models:
      - name: "deepseek/deepseek-r1:free"
        display_name: "DeepSeek R1 (Free)"
        capabilities: ["text_generation", "reasoning"]
        context_length: 32768
        is_free: true
      - name: "deepseek/deepseek-chat:free"
        display_name: "DeepSeek V3 (Free)"
        capabilities: ["text_generation"]
        context_length: 32768
        is_free: true
      - name: "meta-llama/llama-3.3-70b-instruct:free"
        display_name: "Llama 3.3 70B Instruct (Free)"
        capabilities: ["text_generation"]
        context_length: 131072
        is_free: true

  # anthropic:
  #   name: "anthropic"
  #   display_name: "Anthropic"
  #   provider_type: "commercial" # Or "enterprise" depending on your usage
  #   # base_url: "https://api.anthropic.com" # Not strictly needed if SDK handles it
  #   api_key_required: true
  #   auth_header: "x-api-key"
  #   auth_prefix: null # No prefix like "Bearer"
  #   priority: 3 # Adjust as needed
  #   rate_limit: # These are examples, refer to Anthropic's official limits
  #     requests_per_minute: 100
  #     # tokens_per_minute: 600000 # Example, check current limits
  #     concurrent_requests: 10
  #   models:
  #     - name: "claude-3-haiku-20240307"
  #       display_name: "Claude 3 Haiku"
  #       capabilities: ["chat", "code_generation", "summarization"]
  #       # context_length: 200000 # Refer to official documentation
  #       # pricing: # Example, refer to official pricing
  #       #   prompt_tokens_per_usd: 4000000 # $0.25/M input tokens
  #       #   completion_tokens_per_usd: 1333333 # $0.75/M output tokens
  #       is_free: false
  #     - name: "claude-3-sonnet-20240229"
  #       display_name: "Claude 3 Sonnet"
  #       capabilities: ["chat", "code_generation", "summarization", "advanced_reasoning"]
  #       # context_length: 200000
  #       # pricing:
  #       #   prompt_tokens_per_usd: 333333 # $3/M input tokens
  #       #   completion_tokens_per_usd: 66666 # $15/M output tokens
  #       is_free: false
  #     - name: "claude-3-opus-20240229"
  #       display_name: "Claude 3 Opus"
  #       capabilities: ["chat", "code_generation", "summarization", "advanced_reasoning", "complex_tasks"]
  #       # context_length: 200000
  #       # pricing:
  #       #   prompt_tokens_per_usd: 66666 # $15/M input tokens
  #       #   completion_tokens_per_usd: 33333 # $75/M output tokens
  #       is_free: false
  #   default_model: "claude-3-haiku-20240307"
  #   supports_streaming: true
  #   supports_function_calling: false # As of last check, true function calling might be via tools beta
  #   timeout: 60 # Seconds

  groq:
    name: "Groq"
    display_name: "Groq"
    provider_type: "free"
    base_url: "https://api.groq.com/openai/v1"
    priority: 2
    rate_limit:
      requests_per_minute: 30
      requests_per_day: 14400
      tokens_per_minute: 30000
      concurrent_requests: 10
    models:
      - name: "llama-3.3-70b-versatile"
        display_name: "Llama 3.3 70B Versatile"
        capabilities: ["text_generation"]
        context_length: 32768
        is_free: true
      - name: "llama-3.1-8b-instant"
        display_name: "Llama 3.1 8B Instant"
        capabilities: ["text_generation"]
        context_length: 131072
        is_free: true

  cerebras:
    name: "Cerebras"
    display_name: "Cerebras"
    provider_type: "free"
    base_url: "https://api.cerebras.ai/v1"
    priority: 3
    rate_limit:
      requests_per_minute: 30
      tokens_per_minute: 60000
      requests_per_day: 14400
      concurrent_requests: 5
    models:
      - name: "llama3.1-8b"
        display_name: "Llama 3.1 8B"
        capabilities: ["text_generation"]
        context_length: 8192
        is_free: true
      - name: "llama3.3-70b"
        display_name: "Llama 3.3 70B"
        capabilities: ["text_generation"]
        context_length: 8192
        is_free: true

routing_rules:
  - name: "code_generation"
    conditions:
      content_keywords: ["code", "python", "javascript", "programming", "function", "class"]
      capabilities: ["code_generation"]
    provider_preferences: ["openrouter", "groq", "cerebras"]
    fallback_chain: ["openrouter", "groq", "cerebras"]
    is_active: true

  - name: "reasoning"
    conditions:
      content_keywords: ["think", "reason", "solve", "analyze", "logic", "problem"]
      capabilities: ["reasoning"]
    provider_preferences: ["openrouter", "groq"]
    fallback_chain: ["openrouter", "groq", "cerebras"]
    is_active: true

  - name: "fast_response"
    conditions:
      max_tokens: 100
      temperature: 0.0
    provider_preferences: ["groq", "cerebras", "openrouter"]
    fallback_chain: ["groq", "cerebras", "openrouter"]
    is_active: true